(window.webpackJsonp=window.webpackJsonp||[]).push([[19],{271:function(a,s,t){"use strict";t.r(s);var n=t(5),r=Object(n.a)({},(function(){var a=this,s=a.$createElement,t=a._self._c||s;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h1",{attrs:{id:"历史"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#历史"}},[a._v("#")]),a._v(" 历史")]),a._v(" "),t("h2",{attrs:{id:"hadoop-1-x"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hadoop-1-x"}},[a._v("#")]),a._v(" hadoop 1.x")]),a._v(" "),t("p",[a._v("HDFS：用 NameNode 管理 DataNode。\nMap-Reduce：用 JobTracker 管理（调度） TaskTracker")]),a._v(" "),t("h2",{attrs:{id:"hadoop-1-x-map-reduce-的缺点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hadoop-1-x-map-reduce-的缺点"}},[a._v("#")]),a._v(" hadoop 1.x Map-Reduce 的缺点")]),a._v(" "),t("p",[a._v("Map-Reduce 是基于数据集的计算，是面向数据的。")]),a._v(" "),t("ol",[t("li",[a._v("基本的运算规则从介质中获取，计算后再存储到介质中。所以主要应用于一次性计算。在当前的大数据环境中是无法接受的。不适合数据挖掘和机器学习这样的迭代计算。")]),a._v(" "),t("li",[a._v("基于文件，IO 效率慢。")]),a._v(" "),t("li",[a._v("和 hadoop 紧密耦合，无法替换。")])]),a._v(" "),t("h2",{attrs:{id:"hadoop-2-x-yarn-的出现"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hadoop-2-x-yarn-的出现"}},[a._v("#")]),a._v(" hadoop 2.x Yarn 的出现")]),a._v(" "),t("p",[a._v("RM(ResourceManager)\nNM(NodeManager)\nAM(ApplicationMaster)")]),a._v(" "),t("p",[a._v("RM -> NM -> Container -> Task\nRM -> AM -> Driver -> Task")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://imgs-1251264059.cos.ap-chengdu.myqcloud.com/6e7da566-b727-4143-8208-4155ed330775.png",alt:"UTOOLS1592321344280.png"}})]),a._v(" "),t("h2",{attrs:{id:"spark-的出现是为了改善-hadoop-1-x-的不足"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#spark-的出现是为了改善-hadoop-1-x-的不足"}},[a._v("#")]),a._v(" Spark 的出现是为了改善 hadoop 1.x 的不足")]),a._v(" "),t("p",[a._v("基于内存，使用 Scala 语言，适合迭代计算")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://imgs-1251264059.cos.ap-chengdu.myqcloud.com/881e7d36-48a9-48ba-8103-f49da3e5ca15.png",alt:"UTOOLS1592321615415.png"}})]),a._v(" "),t("p",[a._v("HDFS + Yarn + Spark")]),a._v(" "),t("h1",{attrs:{id:"spark-模块"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#spark-模块"}},[a._v("#")]),a._v(" Spark 模块")]),a._v(" "),t("ul",[t("li",[a._v("Spark Core")]),a._v(" "),t("li",[a._v("Spark SQL")]),a._v(" "),t("li",[a._v("Spark Streaming")]),a._v(" "),t("li",[a._v("Spark MLib")]),a._v(" "),t("li",[a._v("Spark GraphX")])]),a._v(" "),t("h1",{attrs:{id:"sbt-管理-jar-包依赖"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#sbt-管理-jar-包依赖"}},[a._v("#")]),a._v(" SBT 管理 jar 包依赖")]),a._v(" "),t("p",[a._v("可以使用下面的方式来定义一个依赖，其中 groupId，artifactId 和 revision 都是字符串：")]),a._v(" "),t("div",{staticClass:"language-ini line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-ini"}},[t("code",[a._v("libraryDependencies +"),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("=")]),a._v(" groupId % artifactId % revision")]),a._v("\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br")])]),t("p",[a._v("使用国内镜像加速：")]),a._v(" "),t("p",[a._v("创建修改 "),t("code",[a._v("~/.sbt/repositories")]),a._v(" 加入阿里的镜像")]),a._v(" "),t("div",{staticClass:"language-ini line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-ini"}},[t("code",[t("span",{pre:!0,attrs:{class:"token selector"}},[a._v("[repositories]")]),a._v("\nlocal\naliyun: https://maven.aliyun.com/repository/public\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br")])]),t("h1",{attrs:{id:"spark-统计单词数量"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#spark-统计单词数量"}},[a._v("#")]),a._v(" Spark 统计单词数量")]),a._v(" "),t("p",[a._v("新建一个 sbt 项目")]),a._v(" "),t("p",[a._v("sbt:")]),a._v(" "),t("div",{staticClass:"language-ini line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-ini"}},[t("code",[a._v("name :"),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("=")]),a._v(' "spark"')]),a._v("\n\nversion :"),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("=")]),a._v(' "0.1"')]),a._v("\n\nscalaVersion :"),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("=")]),a._v(' "2.11.12"')]),a._v("\n\nlibraryDependencies +"),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("=")]),a._v(' "org.apache.spark" %% "spark-core" % "2.4.6"')]),a._v("\nlibraryDependencies +"),t("span",{pre:!0,attrs:{class:"token attr-value"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("=")]),a._v(' "org.apache.spark" %% "spark-sql" % "2.4.6"')]),a._v("\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br"),t("span",{staticClass:"line-number"},[a._v("7")]),t("br"),t("span",{staticClass:"line-number"},[a._v("8")]),t("br")])]),t("p",[a._v("input:")]),a._v(" "),t("div",{staticClass:"language-ini line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-ini"}},[t("code",[a._v("Hello World\nHello Scala\nHello Spark\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br")])]),t("p",[a._v("SparkWordCount:")]),a._v(" "),t("div",{staticClass:"language-scala line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-scala"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token namespace"}},[a._v("org"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("apache"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("spark"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("SparkConf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" SparkContext"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("object")]),a._v(" SparkWordCount "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("def")]),a._v(" main"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("args"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" Array"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("val")]),a._v(" logFile "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"input"')]),a._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("// Should be some file on your system")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("val")]),a._v(" conf "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("new")]),a._v(" SparkConf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n    conf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("setAppName"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"SparkWordCount"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("// 设置应用名称")]),a._v("\n    conf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("setMaster"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"local[1]"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("// 设置本地模式，1个进程")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("val")]),a._v(" sc "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("new")]),a._v(" SparkContext"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("conf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("val")]),a._v(" data "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" sc"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("textFile"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("logFile"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("cache"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("val")]),a._v(" words "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" data"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("flatMap"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("_"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("split"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('" "')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("val")]),a._v(" wordOnce "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" words"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("map"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("_"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("val")]),a._v(" wordWithCountList "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" wordOnce"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("reduceByKey"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("a"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" b"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("=>")]),a._v(" a "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),a._v(" b"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n    wordWithCountList"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("foreach"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("println"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n    sc"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("stop"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br"),t("span",{staticClass:"line-number"},[a._v("7")]),t("br"),t("span",{staticClass:"line-number"},[a._v("8")]),t("br"),t("span",{staticClass:"line-number"},[a._v("9")]),t("br"),t("span",{staticClass:"line-number"},[a._v("10")]),t("br"),t("span",{staticClass:"line-number"},[a._v("11")]),t("br"),t("span",{staticClass:"line-number"},[a._v("12")]),t("br"),t("span",{staticClass:"line-number"},[a._v("13")]),t("br"),t("span",{staticClass:"line-number"},[a._v("14")]),t("br"),t("span",{staticClass:"line-number"},[a._v("15")]),t("br"),t("span",{staticClass:"line-number"},[a._v("16")]),t("br"),t("span",{staticClass:"line-number"},[a._v("17")]),t("br")])]),t("p",[a._v("输出：")]),a._v(" "),t("div",{staticClass:"language-ini line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-ini"}},[t("code",[a._v("(Hello,3)\n(World,1)\n(Scala,1)\n(Spark,1)\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br")])]),t("h1",{attrs:{id:"spark-和-yarn-联合使用"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#spark-和-yarn-联合使用"}},[a._v("#")]),a._v(" Spark 和 Yarn 联合使用")]),a._v(" "),t("p",[a._v("在 spark 目录中修改 spark-env.sh")]),a._v(" "),t("p",[a._v("添加 "),t("code",[a._v("YARN_CONF_DIR=/xxx/hadoop/etc/hadoop")])])])}),[],!1,null,null,null);s.default=r.exports}}]);